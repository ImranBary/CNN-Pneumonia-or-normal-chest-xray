{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ed757916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "train_dir = os.path.join('chest_xray/train/')\n",
    "eval_dir = os.path.join('chest_xray/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "32ca64c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCURACY_THRESHOLD = 0.95\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        if (logs.get('accuracy')>ACCURACY_THRESHOLD):\n",
    "            print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD))\n",
    "            self.model.stop_training = True\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ac89d499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,zoom_range = [0.8,1.2],horizontal_flip = True,rotation_range = 20,shear_range=0.5,fill_mode='constant')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "  train_dir,\n",
    "  batch_size = 12,\n",
    "  target_size=(100, 100),\n",
    "  class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d3ca2315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# All images will be rescaled by 1./255\n",
    "eval_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "eval_generator = eval_datagen.flow_from_directory(\n",
    "  eval_dir,\n",
    "  batch_size = 12,\n",
    "  target_size=(100, 100),\n",
    "  class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c463b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "img = load_img ('chest_xray/train/PNEUMONIA/person423_bacteria_1855.jpeg')\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,)+x.shape)\n",
    "i = 0\n",
    "for batch in train_datagen.flow(x,batch_size=1,\n",
    "                         save_to_dir='augmented',save_prefix='aug',save_format=\"jpeg\"):\n",
    "    i +=1\n",
    "    if i > 20:\n",
    "        break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "95a41082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(3, 3),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a8aaef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_51 (Conv2D)          (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 9, 9, 64)          36928     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 5184)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                331840    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 434,401\n",
      "Trainable params: 434,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2df22e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "42873de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/gcflkw4j1lx_kn_v5p132mym0000gn/T/ipykernel_957/1182610151.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n",
      "2022-05-12 23:43:08.162247: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434/434 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.8249"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 23:43:42.227365: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434/434 [==============================] - 37s 82ms/step - loss: 0.4318 - accuracy: 0.8249 - val_loss: 0.4826 - val_accuracy: 0.7564\n",
      "Epoch 2/50\n",
      "434/434 [==============================] - 35s 81ms/step - loss: 0.2509 - accuracy: 0.9016 - val_loss: 0.2987 - val_accuracy: 0.8862\n",
      "Epoch 3/50\n",
      "434/434 [==============================] - 36s 82ms/step - loss: 0.2153 - accuracy: 0.9245 - val_loss: 0.2937 - val_accuracy: 0.8750\n",
      "Epoch 4/50\n",
      "434/434 [==============================] - 35s 80ms/step - loss: 0.1967 - accuracy: 0.9333 - val_loss: 0.2742 - val_accuracy: 0.8910\n",
      "Epoch 5/50\n",
      "434/434 [==============================] - 35s 80ms/step - loss: 0.1839 - accuracy: 0.9345 - val_loss: 0.3266 - val_accuracy: 0.8750\n",
      "Epoch 6/50\n",
      "434/434 [==============================] - 35s 81ms/step - loss: 0.1620 - accuracy: 0.9427 - val_loss: 0.4235 - val_accuracy: 0.8974\n",
      "Epoch 7/50\n",
      "434/434 [==============================] - 35s 80ms/step - loss: 0.1738 - accuracy: 0.9412 - val_loss: 0.2544 - val_accuracy: 0.9006\n",
      "Epoch 8/50\n",
      "434/434 [==============================] - 35s 80ms/step - loss: 0.1623 - accuracy: 0.9445 - val_loss: 0.2861 - val_accuracy: 0.8846\n",
      "Epoch 9/50\n",
      "434/434 [==============================] - 35s 81ms/step - loss: 0.1592 - accuracy: 0.9481 - val_loss: 0.2925 - val_accuracy: 0.8894\n",
      "Epoch 10/50\n",
      "434/434 [==============================] - 35s 81ms/step - loss: 0.1566 - accuracy: 0.9462 - val_loss: 0.3111 - val_accuracy: 0.8942\n",
      "Epoch 11/50\n",
      "434/434 [==============================] - ETA: 0s - loss: 0.1516 - accuracy: 0.9504\n",
      "Reached 0.95% accuracy, so stopping training!!\n",
      "434/434 [==============================] - 35s 80ms/step - loss: 0.1516 - accuracy: 0.9504 - val_loss: 0.3051 - val_accuracy: 0.8926\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=434,     \n",
    "      epochs=50,\n",
    "      validation_data=eval_generator,\n",
    "      validation_steps= 52,\n",
    "      verbose=1,\n",
    "      callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ee560d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.686933e-22]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 23:50:21.296547: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "\n",
    "img =  image.load_img('norm.jpeg',target_size=(100,100))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis=0)\n",
    "\n",
    "\n",
    "images = np.vstack([x])\n",
    "classes = model.predict(images,batch_size=10)\n",
    "\n",
    "print (classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b73e54bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.96519697]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "\n",
    "img =  image.load_img('chest_xray/train/PNEUMONIA/person348_bacteria_1603.jpeg',target_size=(100,100))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis=0)\n",
    "\n",
    "\n",
    "images = np.vstack([x])\n",
    "classes = model.predict(images,batch_size=10)\n",
    "\n",
    "print (classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d17c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed757916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "train_dir = os.path.join('chest_xray/train/')\n",
    "eval_dir = os.path.join('chest_xray/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac89d499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255,zoom_range=0.2,shear_range=0.2,rotation_range = 20,fill_mode = 'constant')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "  train_dir,\n",
    "  batch_size = 30,\n",
    "  target_size=(256, 256),\n",
    "  class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3ca2315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# All images will be rescaled by 1./255\n",
    "eval_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "eval_generator = eval_datagen.flow_from_directory(\n",
    "  eval_dir,\n",
    "  target_size=(256, 256),\n",
    "  class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95a41082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(3, 3),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    #tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    #tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    #tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8aaef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_58 (Conv2D)          (None, 254, 254, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 84, 84, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 82, 82, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 41, 41, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 39, 39, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 19, 19, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 17, 17, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_60 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_61 (MaxPoolin  (None, 3, 3, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 1, 1, 64)          36928     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 190,657\n",
      "Trainable params: 190,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2df22e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42873de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/gcflkw4j1lx_kn_v5p132mym0000gn/T/ipykernel_6146/995759766.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 14:18:52.040649: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - ETA: 0s - loss: 0.5718 - accuracy: 0.7522"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 14:19:49.621922: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 62s 352ms/step - loss: 0.5718 - accuracy: 0.7522 - val_loss: 0.5143 - val_accuracy: 0.6731\n",
      "Epoch 2/10\n",
      "170/170 [==============================] - 60s 352ms/step - loss: 0.3329 - accuracy: 0.8631 - val_loss: 0.3289 - val_accuracy: 0.8638\n",
      "Epoch 3/10\n",
      "170/170 [==============================] - 60s 352ms/step - loss: 0.2637 - accuracy: 0.8972 - val_loss: 0.2720 - val_accuracy: 0.8894\n",
      "Epoch 4/10\n",
      "170/170 [==============================] - 60s 352ms/step - loss: 0.2133 - accuracy: 0.9152 - val_loss: 0.3813 - val_accuracy: 0.8510\n",
      "Epoch 5/10\n",
      "170/170 [==============================] - 60s 352ms/step - loss: 0.1889 - accuracy: 0.9296 - val_loss: 0.7301 - val_accuracy: 0.6554\n",
      "Epoch 6/10\n",
      "170/170 [==============================] - 60s 351ms/step - loss: 0.1705 - accuracy: 0.9368 - val_loss: 0.2335 - val_accuracy: 0.9103\n",
      "Epoch 7/10\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.1574 - accuracy: 0.9460 - val_loss: 0.2781 - val_accuracy: 0.8974\n",
      "Epoch 8/10\n",
      "170/170 [==============================] - 61s 356ms/step - loss: 0.1461 - accuracy: 0.9464 - val_loss: 0.2322 - val_accuracy: 0.9071\n",
      "Epoch 9/10\n",
      "170/170 [==============================] - 60s 352ms/step - loss: 0.1351 - accuracy: 0.9527 - val_loss: 0.2488 - val_accuracy: 0.8878\n",
      "Epoch 10/10\n",
      "170/170 [==============================] - 60s 351ms/step - loss: 0.1351 - accuracy: 0.9537 - val_loss: 0.2629 - val_accuracy: 0.8990\n"
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=170,\n",
    "        \n",
    "      #batch_size=100,\n",
    "     \n",
    "      epochs=10,\n",
    "      validation_data=eval_generator,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "237a5bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 156ms/step - loss: 0.2629 - accuracy: 0.8990\n",
      "Test accuracy: [0.2628757655620575, 0.8990384936332703]\n"
     ]
    }
   ],
   "source": [
    "test_acc = model.evaluate(eval_generator,batch_size=100, verbose=1) \n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee560d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "\n",
    "img =  image.load_img('norm.jpeg',target_size=(256,256))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis=0)\n",
    "\n",
    "\n",
    "images = np.vstack([x])\n",
    "classes = model.predict(images,batch_size=10)\n",
    "\n",
    "print (classes)\n",
    "print (classes[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73e54bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
